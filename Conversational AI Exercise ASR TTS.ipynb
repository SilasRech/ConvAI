{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "953eca12-4e7e-4226-9e79-03747a1d14cd",
   "metadata": {},
   "source": [
    "Install needed packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a36bd38-f540-4a5b-9d77-86f50af2464a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Requirements\n",
    "!pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab2366f-903c-4524-8c09-c67d5aa5d480",
   "metadata": {},
   "source": [
    "Introducing Whisper for non-real time transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10da8c42-30d4-4f82-bac9-53269ac4df4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "# use internal transcription definition (Quick Way)\n",
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(\"greatpiratestories_00_various.mp3\")\n",
    "print(result[\"text\"])\n",
    "\n",
    "\n",
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(\"greatpiratestories_00_various.mp3\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# decode the audio\n",
    "options = whisper.DecodingOptions(fp16 = False)\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29743586-d8cf-47f4-bd2c-38ee9d6e761e",
   "metadata": {},
   "source": [
    "Introducing Emformer for real-time transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885f881-79e6-4638-b52a-22f2d2c6c0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Requirements \n",
    "!pip install torch\n",
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a4a816-0322-42e7-908f-0e533bb98284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio \n",
    "\n",
    "class ContextCacher:\n",
    "    \"\"\"Cache the end of input data and prepend the next input data with it.\n",
    "\n",
    "    Args:\n",
    "        segment_length (int): The size of main segment.\n",
    "            If the incoming segment is shorter, then the segment is padded.\n",
    "        context_length (int): The size of the context, cached and appended.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, segment_length: int, context_length: int):\n",
    "        self.segment_length = segment_length\n",
    "        self.context_length = context_length\n",
    "        self.context = torch.zeros([context_length])\n",
    "\n",
    "    def __call__(self, chunk: torch.Tensor):\n",
    "        if chunk.size(0) < self.segment_length:\n",
    "            chunk = torch.nn.functional.pad(chunk, (0, self.segment_length - chunk.size(0)))\n",
    "        chunk_with_context = torch.cat((self.context, chunk))\n",
    "        self.context = chunk[-self.context_length :]\n",
    "        return chunk_with_context\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc5fdb-fe35-45d4-87f4-c8de66ada4e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchaudio.io import StreamReader\n",
    "\n",
    "src = \"greatpiratestories_00_various.mp3\"\n",
    "\n",
    "# Get pipeline\n",
    "bundle = torchaudio.pipelines.EMFORMER_RNNT_BASE_LIBRISPEECH\n",
    "\n",
    "feature_extractor = bundle.get_streaming_feature_extractor()\n",
    "decoder = bundle.get_decoder()\n",
    "token_processor = bundle.get_token_processor()\n",
    "\n",
    "sample_rate = bundle.sample_rate\n",
    "segment_length = bundle.segment_length * bundle.hop_length\n",
    "context_length = bundle.right_context_length * bundle.hop_length\n",
    "\n",
    "# Stream Audio File\n",
    "streamer = StreamReader(src)\n",
    "streamer.add_basic_audio_stream(frames_per_chunk=segment_length, sample_rate=bundle.sample_rate)\n",
    "\n",
    "state, hypothesis = None, None    \n",
    "cacher = ContextCacher(segment_length, context_length)\n",
    "\n",
    "stream_iterator = streamer.stream()\n",
    "\n",
    "# Run speech recognition\n",
    "@torch.inference_mode()\n",
    "def run_inference(num_iter=1000):\n",
    "    global state, hypothesis\n",
    "    chunks = []\n",
    "    feats = []\n",
    "    for i, (chunk,) in enumerate(stream_iterator, start=1):\n",
    "        segment = cacher(chunk[:, 0])\n",
    "        features, length = feature_extractor(segment)\n",
    "        hypos, state = decoder.infer(features, length, 10, state=state, hypothesis=hypothesis)\n",
    "        hypothesis = hypos\n",
    "        transcript = token_processor(hypos[0][0], lstrip=False)\n",
    "        print(transcript, end=\"\\r\", flush=True)\n",
    "\n",
    "        chunks.append(chunk)\n",
    "        feats.append(features)\n",
    "        if i == num_iter:\n",
    "            break\n",
    "\n",
    "run_inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208fa12c-e39a-4b2b-8848-f8904c43101a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Speech Synthesis Tacotron \n",
    "\n",
    "More Links to check out:\n",
    "https://google.github.io/tacotron/publications/tacotron2/index.html\n",
    "https://github.com/suno-ai/bark\n",
    "https://github.com/coqui-ai/TTS\n",
    "\n",
    "Speech Brain\n",
    "https://github.com/speechbrain/speechbrain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b95303e2-d972-427d-b5cd-10efa733a186",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/software/lib/python3.10/site-packages (1.23.5)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cvxpy 1.4.1 requires pybind11, which is not installed.\n",
      "spectrum 0.8.1 requires easydev, which is not installed.\n",
      "tts 0.22.0 requires numpy==1.22.0; python_version <= \"3.10\", but you have numpy 1.26.4 which is incompatible.\n",
      "pystan 3.7.0 requires httpstan<4.11,>=4.10, but you have httpstan 4.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "#!pip install git+https://github.com/huggingface/transformers.git\n",
    "!pip3 install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14abf66a-dbb6-4355-8b41-387465f736fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting speechbrain\n",
      "  Downloading speechbrain-1.0.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting hyperpyyaml (from speechbrain)\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: joblib in /opt/software/lib/python3.10/site-packages (from speechbrain) (1.3.2)\n",
      "Requirement already satisfied: numpy in /opt/software/lib/python3.10/site-packages (from speechbrain) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/software/lib/python3.10/site-packages (from speechbrain) (23.2)\n",
      "Requirement already satisfied: scipy in /opt/software/lib/python3.10/site-packages (from speechbrain) (1.11.3)\n",
      "Collecting sentencepiece (from speechbrain)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: torch>=1.9 in /opt/software/lib/python3.10/site-packages (from speechbrain) (2.1.1)\n",
      "Requirement already satisfied: torchaudio in /opt/software/lib/python3.10/site-packages (from speechbrain) (2.1.1)\n",
      "Requirement already satisfied: tqdm in /opt/software/lib/python3.10/site-packages (from speechbrain) (4.65.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/software/lib/python3.10/site-packages (from speechbrain) (0.22.2)\n",
      "Requirement already satisfied: filelock in /opt/software/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/software/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/software/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/software/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /opt/software/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/software/lib/python3.10/site-packages (from torch>=1.9->speechbrain) (2023.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/software/lib/python3.10/site-packages (from huggingface-hub->speechbrain) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/software/lib/python3.10/site-packages (from huggingface-hub->speechbrain) (2.31.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /opt/software/lib/python3.10/site-packages (from hyperpyyaml->speechbrain) (0.17.32)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/software/lib/python3.10/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/software/lib/python3.10/site-packages (from jinja2->torch>=1.9->speechbrain) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/software/lib/python3.10/site-packages (from requests->huggingface-hub->speechbrain) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/software/lib/python3.10/site-packages (from requests->huggingface-hub->speechbrain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/software/lib/python3.10/site-packages (from requests->huggingface-hub->speechbrain) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/software/lib/python3.10/site-packages (from requests->huggingface-hub->speechbrain) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/software/lib/python3.10/site-packages (from sympy->torch>=1.9->speechbrain) (1.3.0)\n",
      "Downloading speechbrain-1.0.0-py3-none-any.whl (760 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.1/760.1 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, hyperpyyaml, speechbrain\n",
      "Successfully installed hyperpyyaml-1.2.2 sentencepiece-0.2.0 speechbrain-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install speechbrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8517dfb9-5d5f-4267-8f8d-db5ae7ad8857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from speechbrain.inference.TTS import Tacotron2\n",
    "from speechbrain.inference.vocoders import HIFIGAN\n",
    "\n",
    "# Intialize TTS (tacotron2) and Vocoder (HiFIGAN)\n",
    "tacotron2 = Tacotron2.from_hparams(source=\"speechbrain/tts-tacotron2-ljspeech\", savedir=\"tmpdir_tts\")\n",
    "hifi_gan = HIFIGAN.from_hparams(source=\"speechbrain/tts-hifigan-ljspeech\", savedir=\"tmpdir_vocoder\")\n",
    "\n",
    "# Running the TTS\n",
    "mel_output, mel_length, alignment = tacotron2.encode_text(\"This is a test recording usingg Tacotron 2 with Hifi-Gan\")\n",
    "\n",
    "# Running Vocoder (spectrogram-to-waveform)\n",
    "waveforms = hifi_gan.decode_batch(mel_output)\n",
    "\n",
    "# Save the waverform\n",
    "torchaudio.save('example_TTS.wav',waveforms.squeeze(1), 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1765d4-443e-4a04-98e1-b19cdb9cfba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
